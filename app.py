import streamlit as st
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
import matplotlib.pyplot as plt
import seaborn as sns

# --- Configuration ---
DATA_URL = "https://raw.githubusercontent.com/Kaustav2500/emailSpamDetection/main/email_spam.csv"

# --- Data Loading and Caching ---

@st.cache_data
def load_data():
    """Loads, cleans, and preprocesses the dataset."""
    try:
        # Load data from the specified GitHub URL
        df = pd.read_csv(DATA_URL, encoding='ISO-8859-1')
        
        # Preprocessing steps from the notebook
        df.rename(columns={"v1": "Category", "v2": "Message"}, inplace=True)
        df.drop(columns={'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'}, inplace=True)
        df.drop_duplicates(inplace=True)
        df['Spam'] = df['Category'].apply(lambda x: 1 if x == 'spam' else 0)
        
        return df
    except Exception as e:
        st.error(f"Error loading or processing data: {e}")
        return pd.DataFrame()

@st.cache_resource
def train_model(df):
    """Trains the Spam detection pipeline (Vectoriser + Naive Bayes)."""
    if df.empty:
        return None

    # Splitting the data based on notebook logic (no explicit random_state given, but using one for reproducibility)
    X = df.Message
    y = df.Spam

    # Create the pipeline (CountVectorizer + MultinomialNB)
    clf = Pipeline([
        ('vectorizer', CountVectorizer()),
        ('nb', MultinomialNB())
    ])
    
    # Fit the model on the entire dataset for better prediction accuracy in the app
    clf.fit(X, y)
    return clf

# --- Streamlit App UI ---

# Load data and train model
data_df = load_data()
model_pipeline = train_model(data_df)

st.set_page_config(
    page_title="Email Spam Detector",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Title and Description
st.title("‚úâÔ∏è Email Spam Detector")
st.markdown("A simple web tool built using Streamlit and a Multinomial Naive Bayes classifier, based on the provided Jupyter notebook project.")

if model_pipeline is None:
    st.stop()

# --- Prediction Interface ---

st.header("Try it out!")
email_text = st.text_area(
    "Enter an email message below:", 
    "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075",
    height=200
)

# Prediction Button
if st.button("Analyze Message", type="primary"):
    if email_text:
        # Make prediction
        prediction = model_pipeline.predict([email_text])[0]
        
        # Get probability (for confidence)
        probability = model_pipeline.predict_proba([email_text])[0]
        confidence = max(probability) * 100

        st.markdown("---")
        
        if prediction == 1:
            st.error(f"üö® This is a **SPAM** Email!")
            st.subheader(f"Confidence: {confidence:.2f}%")
        else:
            st.success(f"‚úÖ This is a **HAM** (Legitimate) Email!")
            st.subheader(f"Confidence: {confidence:.2f}%")
    else:
        st.warning("Please enter a message to analyze.")

# --- Optional EDA and Model Stats ---

st.sidebar.header("Project Insights")

# Distribution Chart
st.sidebar.subheader("Spam vs. Ham Distribution")
fig, ax = plt.subplots()
spread = data_df['Category'].value_counts()
spread.plot(kind='pie', autopct='%1.1f%%', ax=ax, colors=['#4CAF50', '#FF5733'])
ax.set_ylabel('')
ax.set_title("Dataset Balance")
st.sidebar.pyplot(fig)

# Model Performance Summary (Using hardcoded values from notebook output for simplicity)
st.sidebar.subheader("Model Performance (MultinomialNB)")
st.sidebar.info(
    "The model achieves high performance, prioritizing **Precision** and **Recall** for the spam class (label '1')."
)

col1, col2 = st.sidebar.columns(2)
with col1:
    st.metric(label="Test Accuracy", value="98.92%")
    st.metric(label="Spam Precision", value="96.25%")
with col2:
    st.metric(label="Test ROC-AUC", value="0.9700")
    st.metric(label="Spam Recall", value="94.48%")

st.sidebar.markdown(
    "--- \n *Note: Metrics are based on the training/testing split in the original notebook.*"
)

# --- Run the app ---
# To run this app, save the files and execute: streamlit run app.py